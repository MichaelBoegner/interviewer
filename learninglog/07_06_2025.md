from pathlib import Path

learning_log = """
# Learning Log

## ðŸ¤” Discovery of the Day  
Embedding-based retrieval with `pgvector` is cleanest when implemented as a microservice, and integrates more naturally than Faiss in apps that already use PostgreSQL.

While building Retrieval-Augmented Generation (RAG) support for my mock interview app, I explored options for storing and searching embeddings. Although Faiss is widely used, I realized that `pgvector` is a better match for my tech stack, offering SQL-native similarity search, simpler deployment, and tighter integration with Go and PostgreSQL.

### âœ… Learnings  

#### ðŸ§  How Vector Embeddings Work  
1. Language models like `sentence-transformers` convert text into dense numerical vectors in high-dimensional space (e.g. 384 or 768 dimensions).
2. These vectors preserve semantic relationships: texts with similar meaning are closer together in vector space.
3. You canâ€™t decode embeddings back into the original sentence â€” they arenâ€™t encrypted strings, just a lossy semantic representation.
4. To find similar content, you embed a user query, then perform approximate nearest neighbor (ANN) search to find stored vectors that are "closest" in meaning.
5. Maintain meta data in embedding table to maintain relevant semantic searches. 

#### ðŸ§± Why pgvector over Faiss

- **Integrates with PostgreSQL**: pgvector is a native extension, while Faiss requires a separate storage engine.
- **Local Dev Simplicity**: pgvector only needs `CREATE EXTENSION pgvector`, while Faiss needs an extra daemon or service.
- **Query Language**: pgvector uses standard SQL, while Faiss is Python/C++ API only.
- **Metadata Sync**: pgvector allows storing metadata in the same row; Faiss does not.
- **Deployment**: pgvector fits into a single Postgres container; Faiss is more complex to deploy.
- **Go Integration**: pgvector works with standard SQL drivers; Faiss needs bindings or workarounds.

Summary: pgvector is more portable, maintainable, and scalable for full-stack apps already using Postgres. Faiss is faster at huge scale (millions of vectors), but overkill for typical SaaS workloads. Also, `pgvector` is free! 

#### ðŸ”Œ Microservice: `interviewer-embedding`  

1. **Service Choice**  
   - Embedding done in Python using `FastAPI` + `sentence-transformers`
   - Go backend sends text, receives embedding vector`

2. **Endpoints**  
   - `POST /embed_context`: used to embed past answers/questions for later search  
   - `POST /embed_query`: used to embed the live user question for context lookup

3. **Schemas**  
   ```python
    class QueryEmbedRequest(BaseModel):
        text: str

    class EmbedChunk(BaseModel):
        topic_number: int
        question_number: int
        text: str

    class ContextEmbedRequest(BaseModel):
        chunks: List[EmbedChunk]

    class QueryEmbedResponse(BaseModel):
        embeddings: List[float]
        
    class ContextEmbedResponse(BaseModel):
        embeddings: List[List[float]]


